# Multi-Label-KNN

Implement multi-label k-nearest neighbors (k-NN) classifier as an extension of traditional k-NN algorithm for the given dataset. (In multi-label classification, each instance can be associated with multiple labels, as opposed to single-label classification where each instance is assigned to just one label).
Apply pre-processing on the given text dataset 'train.csv'
Work for feature extraction/selection
Run your model for k-fold cross-validation
Evaluate the performance of the multi-label k-NN model for test data 'test.csv' using metric Hamming Loss and F1 score.
Tune the hyperparameters like the value of k(number of neighbors) and distance metric.
